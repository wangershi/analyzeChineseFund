import pandas as pd
import configparser
import fire
import os
import math
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
matplotlib.use('Agg')

from sklearn.metrics.pairwise import cosine_similarity

import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '../../'))

from src.utils.util import getLatestFile

def analyzeHistoricalValue(ifUseNewIssues = True, ifUseOldIssues = True, ifUseWatchList = False, ifUseAdjustFactorToLatestDay = False, ifPrintFundCode = False):
    '''
        Args:
            ifUseNewIssues: if use those funds whose days range are less than daysRangeToAnalyze
            ifUseOldIssues: if use those funds whose days range are more than daysRangeToAnalyze
            ifUseWatchList: if only figure funds in config/watchlist.txt
            ifUseAdjustFactorToLatestDay: if use adjustFactorToLatestDay generated by trainGBDT.py
            ifPrintFundCode: if print fund code, if so, the image would be larger
    '''
    print ("Begin to analyze historical value...")
    # read config file
    cf = configparser.ConfigParser()
    cf.read("config/config.ini")
    folderOfFundInformation = cf.get("Data-Crawler", "folderOfFundInformation")
    daysRangeInOneYear = int(cf.get("Data-Prepare", "daysRangeInOneYear"))  # 252 is the trading days in one year
    numberOfYears = int(cf.get("Data-Prepare", "numberOfYears"))
    minDaysRange = int(cf.get("Data-Prepare", "minDaysRange"))
    folderToSaveHistoricalValue = cf.get("Data-Crawler", "folderToSaveHistoricalValue")
    daysRangeToAnalyze = daysRangeInOneYear * numberOfYears

    if ifUseAdjustFactorToLatestDay:
        dfAdjustFactorToLatestDay = pd.read_csv("data/dfAdjustFactorToLatestDay.csv", dtype={'Unnamed: 0':object})

    # read watchlist
    watchlist = []  # ['110011', '161028', '110020', '180003', '006479', '007994', '001015']
    for line in  open("./config/watchlist.txt", "r"):
        watchlist.append(line.split("\n")[0])

    # we should ignore some strange funds
    ignorelist = [] # ['009317', '009763', '009764']
    for line in  open("./config/ignorelist.txt", "r"):
        ignorelist.append(line.split("\n")[0])

    # read fund information
    latestFundInformation = getLatestFile(folderOfFundInformation)
    month = latestFundInformation.split(".")[0].split("_")[-1]
    dfForFundInformation = pd.read_csv(os.path.join(folderOfFundInformation, latestFundInformation), dtype=object)

    # use one fund be the standard of trading day
    pathOfFileStandard = os.path.join(folderToSaveHistoricalValue, "000934_%s.csv" % month)
    dfStandard = pd.read_csv(pathOfFileStandard)
    dfStandard['Date'] = pd.to_datetime(dfStandard['Date'])
    dfStandard = dfStandard.head(daysRangeToAnalyze)
    dateStandard = dfStandard["Date"]
    firstDay = dateStandard[dateStandard.first_valid_index()]
    lastDay = dateStandard[dateStandard.last_valid_index()] # 2017-12-20 00:00:00

    count = 0
    riskListForOldIssues = []
    returnListForOldIssues = []
    fundCodeListForOldIssues = []
    riskListForNewIssues = []
    returnListForNewIssues = []
    fundCodeListForNewIssues = []
    for file in os.listdir(folderToSaveHistoricalValue):
        fundCode = file.split("_")[0]

        # exclude some funds
        if fundCode in ignorelist:
            continue

        if ifUseWatchList and fundCode not in watchlist:
            continue

        if count % 100 == 0:
            print ("\ncount = %s\tfundCode = %s" % (count, fundCode))  # 180003
        try:
            df = pd.read_csv(os.path.join(folderToSaveHistoricalValue, file))

            # remove empty line
            df = df.dropna(axis=0, subset=['AccumulativeNetAssetValue'])

            # like http://fundf10.eastmoney.com/jjjz_010476.html, the return in 30 days is 26%, so the annualized return is too high
            if df.shape[0] <= minDaysRange:
                continue

            # get growth ratio for AccumulativeNetAssetValue
            df["PreviousValue"] = df["AccumulativeNetAssetValue"].shift(-1)
            df["GrowthRatio"] = (df["AccumulativeNetAssetValue"] - df["PreviousValue"]) / df["PreviousValue"]
            
            # abandom those values before the date when GrowthRatio is too large (abs >= 1.0)
            df["AbsoluteGrowthRatio"] = df["GrowthRatio"].abs()
            if df[df["AbsoluteGrowthRatio"] > 1].shape[0] > 0:
                df = df.loc[0:df[df["AbsoluteGrowthRatio"] > 1].first_valid_index() - 1]

            # reset the index
            df = df.dropna(axis=0, subset=['GrowthRatio'])
            df.reset_index(drop=True, inplace=True)

            # only choose much days
            df['Date'] = pd.to_datetime(df['Date'])
            df = df[df["Date"] <= firstDay]
            df = df[df["Date"] >= lastDay]

            # too less data
            if df.shape[0] <= minDaysRange:
                continue

            netValue = df["AccumulativeNetAssetValue"]
            earliestNetValue = netValue[netValue.last_valid_index()]    # 3.004
            lastestNetValue = netValue[netValue.first_valid_index()]

            # count the days between first day and last day
            day = df['Date']
            firstDayInStandard = dfStandard[dfStandard['Date'] == day[day.first_valid_index()]].index
            lastDayInStandard = dfStandard[dfStandard['Date'] == day[day.last_valid_index()]].index
            try:
                countNetValue = (lastDayInStandard - firstDayInStandard)._data[0]
            except:
                # TODO: how about fund 519858, which trade in 2018-01-28 (Sunday)
                continue
            countNetValue += 1
            #print ("countNetValue = %s" % countNetValue)   # 756
            
            # standardrize the risk in one year
            # assume the value is a list like (0, 1, 0, 1,...), growth ratio is a list like (1, -1, 1, -1,...)
            # set ddof be 0 to standardrize the risk by n, not (n - 1), then the std is 1, not related to countNetValue
            riskCurrent = df["GrowthRatio"].std(ddof=0)
            returnCurrent = (lastestNetValue-earliestNetValue)/earliestNetValue/countNetValue*daysRangeInOneYear

            if not ifUseNewIssues:
                if countNetValue < daysRangeToAnalyze:
                    continue
            else:
                # use latest value to reflect the true percentage gain
                # this is worthful if the fund rise rapidly recently but have no change in long previous days
                if ifUseAdjustFactorToLatestDay:
                    if countNetValue < daysRangeToAnalyze:
                        # if the fund code locates in dfAdjustFactorToLatestDay
                        try:
                            # adjust the latest value and days range
                            adjustedFactor = dfAdjustFactorToLatestDay[fundCode]
                            adjustedFactor = adjustedFactor[adjustedFactor.first_valid_index()] # 0.987561058590916
                            lastestNetValue = lastestNetValue * adjustedFactor
                            returnCurrent = (lastestNetValue-earliestNetValue)/earliestNetValue/daysRangeToAnalyze*daysRangeInOneYear
                        except Exception as e:
                            print (e)
                            continue

            # new issues
            if countNetValue < daysRangeToAnalyze:
                riskListForNewIssues.append(riskCurrent)
                returnListForNewIssues.append(returnCurrent)
                fundCodeListForNewIssues.append(fundCode)
            else:
                riskListForOldIssues.append(riskCurrent)
                returnListForOldIssues.append(returnCurrent)
                fundCodeListForOldIssues.append(fundCode)
                
            count += 1
        except Exception as e:
            raise e

    if not ifUseWatchList and ifPrintFundCode:
        plt.figure(figsize=(10, 10))
    if ifUseOldIssues:
        plt.scatter(riskListForOldIssues, returnListForOldIssues, c='k')
    if ifUseNewIssues:
        plt.scatter(riskListForNewIssues, returnListForNewIssues, c='k')
    plt.xlabel("Risk")
    plt.ylabel("Annualized return")

    plt.xlim((0, 0.06))
    plt.ylim((-0.4, 1.4))
    ax = plt.gca()
    # no line in right and top border
    ax.spines['right'].set_color('none')
    ax.spines['top'].set_color('none')

    if ifPrintFundCode:
        if ifUseOldIssues:
            for i in range(len(fundCodeListForOldIssues)):
                x = riskListForOldIssues[i]
                y = returnListForOldIssues[i]
                fundCode = fundCodeListForOldIssues[i]
                plt.text(x, y, fundCode, fontsize=10)

        if ifUseNewIssues:
            for i in range(len(fundCodeListForNewIssues)):
                x = riskListForNewIssues[i]
                y = returnListForNewIssues[i]
                fundCode = fundCodeListForNewIssues[i]
                plt.text(x, y, fundCode, fontsize=10)

    nameOfPicture = "risk_return"
    if ifUseWatchList:
        nameOfPicture += "_watchlist"
    else:
        nameOfPicture += "_noWatchlist"

    if ifUseNewIssues:
        nameOfPicture += "_useNewIssues"
    else:
        nameOfPicture += "_notUseNewIssues"

    if ifUseOldIssues:
        nameOfPicture += "_useOldIssues"
    else:
        nameOfPicture += "_notUseOldIssues"

    if ifUseAdjustFactorToLatestDay:
        nameOfPicture += "_useAdjustFactor"
    else:
        nameOfPicture += "_notUseAdjustFactor"

    plt.savefig("./image/%s.png" % nameOfPicture)
    print ("END.")


def getHistoricalValue():
    print ("Begin to get historical value...")
    # read config file
    cf = configparser.ConfigParser()
    cf.read("config/config.ini")
    daysRangeInOneYear = int(cf.get("Data-Prepare", "daysRangeInOneYear"))  # 252 is the trading days in one year
    numberOfYears = int(cf.get("Data-Prepare", "numberOfYears"))
    daysRangeToAnalyze = daysRangeInOneYear * numberOfYears
    minDaysRange = int(cf.get("Data-Prepare", "minDaysRange"))
    folderOfDayInStandard = cf.get("Data-Analyze", "folderOfDayInStandard")
    folderToSaveHistoricalValue = cf.get("Data-Crawler", "folderToSaveHistoricalValue")
    folderOfFundInformation = cf.get("Data-Crawler", "folderOfFundInformation")

    # we should ignore some strange funds
    ignorelist = [] # ['009317', '009763', '009764']
    for line in  open("./config/ignorelist.txt", "r"):
        ignorelist.append(line.split("\n")[0])

    # read fund information
    latestFundInformation = getLatestFile(folderOfFundInformation)
    month = latestFundInformation.split(".")[0].split("_")[-1]
    dfForFundInformation = pd.read_csv(os.path.join(folderOfFundInformation, latestFundInformation), dtype=object)

    # use one fund be the standard of trading day
    pathOfFileStandard = os.path.join(folderToSaveHistoricalValue, "000934_%s.csv" % month)
    dfStandard = pd.read_csv(pathOfFileStandard)
    dfStandard['Date'] = pd.to_datetime(dfStandard['Date'])
    dfStandard = dfStandard.head(daysRangeToAnalyze)
    dateStandard = dfStandard["Date"]
    firstDay = dateStandard[dateStandard.first_valid_index()]
    lastDay = dateStandard[dateStandard.last_valid_index()] # 2017-12-20 00:00:00

    # save data in this folder
    if not os.path.exists(folderOfDayInStandard):
        os.mkdir(folderOfDayInStandard)

    count = 0
    for file in os.listdir(folderToSaveHistoricalValue):
        fundCode = file.split("_")[0]

        # exclude some funds
        if fundCode in ignorelist:
            continue

        if count % 100 == 0:
            print ("count = %s\tfundCode = %s" % (count, fundCode))  # 180003
        try:
            pathOfFile = os.path.join(folderToSaveHistoricalValue, file)
            df = pd.read_csv(pathOfFile)

            # remove empty line
            df = df.dropna(axis=0, subset=['AccumulativeNetAssetValue'])

            # like http://fundf10.eastmoney.com/jjjz_010476.html, the return in 30 days is 26%, so the annualized return is too high
            if df.shape[0] <= minDaysRange:
                continue

            # get growth ratio for AccumulativeNetAssetValue
            df["PreviousValue"] = df["AccumulativeNetAssetValue"].shift(-1)
            df["GrowthRatio"] = (df["AccumulativeNetAssetValue"] - df["PreviousValue"]) / df["PreviousValue"]
            
            # abandom those values before the date when GrowthRatio is too large (abs >= 1.0)
            df["AbsoluteGrowthRatio"] = df["GrowthRatio"].abs() # 346
            if df[df["AbsoluteGrowthRatio"] > 1].shape[0] > 0:
                df = df.loc[0:df[df["AbsoluteGrowthRatio"] > 1].first_valid_index() - 1]

            # reset the index
            df = df.dropna(axis=0, subset=['GrowthRatio'])
            df.reset_index(drop=True, inplace=True)

            # only choose much days
            df['Date'] = pd.to_datetime(df['Date'])
            df = df[df["Date"] <= firstDay]
            df = df[df["Date"] >= lastDay]

            # too less data
            if df.shape[0] <= minDaysRange:
                continue

            listOfDayInStandard = []
            for index, row in df.iterrows():
                try:
                    indexOfDayInStandard = dfStandard[dfStandard['Date'] == df.loc[index]['Date']].index
                    listOfDayInStandard.append(indexOfDayInStandard._data[0])
                # cannot find this day in standardFund
                except:
                    listOfDayInStandard.append(-1)
            df.insert(0, 'DayInStandard', listOfDayInStandard)

            # save data
            pathToSave = os.path.join(folderOfDayInStandard, file)
            df.to_csv(pathToSave)

            count += 1
        except Exception as e:
            raise e

    print ("END.")

def getAverageSlopeForFundsInSameRange(ifUseAdjustFactorToLatestDay=True):
    '''
        in return-risk figure, the return is proportional to risk in most cases,
        so we can use slope(return/risk) as the feature of this fund, if we want
        to summarize funds in same range, we can use average slope to represent it.
    '''
    print ("Begin to get average slope for funds in same range...")

    # read config file
    cf = configparser.ConfigParser()
    cf.read("config/config.ini")
    daysRangeInOneYear = int(cf.get("Data-Prepare", "daysRangeInOneYear"))  # 252 is the trading days in one year
    numberOfYears = int(cf.get("Data-Prepare", "numberOfYears"))
    daysRangeToAnalyze = daysRangeInOneYear * numberOfYears
    divideNumber = int(cf.get("Data-Analyze", "divideNumber"))
    folderOfDayInStandard = cf.get("Data-Analyze", "folderOfDayInStandard")

    # if use adjustFactorToLatestDay generated by trainGBDT.py
    if ifUseAdjustFactorToLatestDay:
        dfAdjustFactorToLatestDay = pd.read_csv("data/dfAdjustFactorToLatestDay.csv", dtype={'Unnamed: 0':object})

    if not os.path.exists(folderOfDayInStandard):
        os.mkdir(folderOfDayInStandard)
    # didn't generate dayInStandard before
    if len(os.listdir(folderOfDayInStandard)) <= 0:
        getHistoricalValue()

    dictOfSlopeInCountNetValue = {}
    dictOfReturnInCountNetValue = {}
    dictOfRiskInCountNetValue = {}

    count = 0
    for file in os.listdir(folderOfDayInStandard):
        fundCode = file.split("_")[0]

        if count % 100 == 0:
            print ("count = %s\tfundCode = %s" % (count, fundCode))  # 180003

        try:
            pathOfFile = os.path.join(folderOfDayInStandard, file)
            df = pd.read_csv(pathOfFile)

            netValue = df["AccumulativeNetAssetValue"]
            earliestNetValue = netValue[netValue.last_valid_index()]    # 3.004
            lastestNetValue = netValue[netValue.first_valid_index()]

            dayInStandard = df["DayInStandard"]
            firstDayInStandard = dayInStandard[dayInStandard.first_valid_index()]
            lastDayInStandard = dayInStandard[dayInStandard.last_valid_index()]
            countNetValue = lastDayInStandard - firstDayInStandard + 1  # 756

            # TODO: standardrize the risk in one year
            # assume the value is a list like (0, 1, 0, 1,...), growth ratio is a list like (1, -1, 1, -1,...)
            # set ddof be 0 to standardrize the risk by n, not (n - 1), then the std is 1, not related to countNetValue
            riskCurrent = df["GrowthRatio"].std(ddof=0) # 0.014161537768387899

            # use latest value to reflect the true percentage gain
            # this is worthful if the fund rise rapidly recently but have no change in long previous days
            countNetValueAdjusted = countNetValue
            if ifUseAdjustFactorToLatestDay:
                if countNetValue < daysRangeToAnalyze:
                    # if the fund code locates in dfAdjustFactorToLatestDay
                    try:
                        # adjust the latest value and days range
                        adjustedFactor = dfAdjustFactorToLatestDay[fundCode]
                        adjustedFactor = adjustedFactor[adjustedFactor.first_valid_index()]
                        lastestNetValue = lastestNetValue * adjustedFactor
                        countNetValueAdjusted = daysRangeToAnalyze
                    except Exception as e:
                        print (e)
                        continue

            # use latest value to reflect the true percentage gain
            # this is worthful if the fund rise rapidly recently but have no change in long previous days
            returnCurrent = (lastestNetValue-earliestNetValue)/earliestNetValue/countNetValueAdjusted*daysRangeInOneYear    # 0.3984541490442937

            slope = returnCurrent / riskCurrent # 28.136361711631576

            # TODO: exclude 005337
            if math.isnan(slope):
                continue

            # count them in period, not a single day
            approximateCountValue = countNetValue // divideNumber * divideNumber

            if approximateCountValue not in dictOfSlopeInCountNetValue.keys():
                dictOfSlopeInCountNetValue[approximateCountValue] = []
            dictOfSlopeInCountNetValue[approximateCountValue].append(slope)

            if approximateCountValue not in dictOfReturnInCountNetValue.keys():
                dictOfReturnInCountNetValue[approximateCountValue] = []
            dictOfReturnInCountNetValue[approximateCountValue].append(returnCurrent)

            if approximateCountValue not in dictOfRiskInCountNetValue.keys():
                dictOfRiskInCountNetValue[approximateCountValue] = []
            dictOfRiskInCountNetValue[approximateCountValue].append(riskCurrent)

            count += 1
        except Exception as e:
            raise e

    #print (dictOfSlopeInCountNetValue)
    plt.xlim((0, 800))
    plt.ylim((-40, 100))
    plt.xlabel("Count of trading days")
    plt.ylabel("Return/Risk")
    ax = plt.gca()
    # no line in right and top border
    ax.spines['right'].set_color('none')
    ax.spines['top'].set_color('none')
    for key in dictOfSlopeInCountNetValue.keys():
        # Number of observations
        n = len(dictOfSlopeInCountNetValue[key])
        # Mean of the data
        mean = sum(dictOfSlopeInCountNetValue[key]) / n
        # Square deviations
        deviations = [(x - mean) ** 2 for x in dictOfSlopeInCountNetValue[key]]
        # standard deviation
        standardDeviation = math.sqrt(sum(deviations) / n)

        plt.errorbar(key, mean, standardDeviation, c='k', marker='+')

    nameOfReturnRisk = "averageSlopeForReturnRisk_%s" % divideNumber

    if ifUseAdjustFactorToLatestDay:
        nameOfReturnRisk += "_useAdjustFactor"
    else:
        nameOfReturnRisk += "_notUseAdjustFactor"

    plt.savefig("./image/%s.png" % nameOfReturnRisk)

    #print (dictOfReturnInCountNetValue)
    plt.clf()
    plt.xlim((0, 800))
    plt.ylim((-0.2, 0.6))
    plt.xlabel("Count of trading days")
    plt.ylabel("Return")
    ax = plt.gca()
    # no line in right and top border
    ax.spines['right'].set_color('none')
    ax.spines['top'].set_color('none')
    listOfMean = []
    for key in dictOfReturnInCountNetValue.keys():
        # Number of observations
        n = len(dictOfReturnInCountNetValue[key])
        # Mean of the data
        mean = sum(dictOfReturnInCountNetValue[key]) / n
        listOfMean.append(mean)
        # Square deviations
        deviations = [(x - mean) ** 2 for x in dictOfReturnInCountNetValue[key]]
        # standard deviation
        standardDeviation = math.sqrt(sum(deviations) / n)

        plt.errorbar(key, mean, standardDeviation, c='k', marker='+')

    nameOfReturn = "averageReturn_%s" % divideNumber

    # get the standard deviation of mean
    standardDeviationOfReturn = np.std(listOfMean, ddof = 0)
    print ("standardDeviationOfReturn = %s" % standardDeviationOfReturn)

    if ifUseAdjustFactorToLatestDay:
        nameOfReturn += "_useAdjustFactor"
    else:
        nameOfReturn += "_notUseAdjustFactor"
    plt.savefig("./image/%s.png" % nameOfReturn)

    #print (dictOfRiskInCountNetValue)
    plt.clf()
    plt.xlim((0, 800))
    plt.ylim((-0.005, 0.02))
    plt.xlabel("Count of trading days")
    plt.ylabel("Risk")
    ax = plt.gca()
    # no line in right and top border
    ax.spines['right'].set_color('none')
    ax.spines['top'].set_color('none')
    for key in dictOfRiskInCountNetValue.keys():
        # Number of observations
        n = len(dictOfRiskInCountNetValue[key])
        # Mean of the data
        mean = sum(dictOfRiskInCountNetValue[key]) / n
        # Square deviations
        deviations = [(x - mean) ** 2 for x in dictOfRiskInCountNetValue[key]]
        # standard deviation
        standardDeviation = math.sqrt(sum(deviations) / n)

        plt.errorbar(key, mean, standardDeviation, c='k', marker='+')

    nameOfRisk = "averageRisk_%s" % divideNumber

    if ifUseAdjustFactorToLatestDay:
        nameOfRisk += "_useAdjustFactor"
    else:
        nameOfRisk += "_notUseAdjustFactor"
    plt.savefig("./image/%s.png" % nameOfRisk)

    print ("END.")


def getCorrelationMatrixForOneFund(ifGetCorrFromFile = True, ifGetDfMergeFromFile = True):
    print ("Begin to get Pearson's correlation matrix for fund '110011'...")
    # read config file
    cf = configparser.ConfigParser()
    cf.read("config/config.ini")
    folderOfDayInStandard = cf.get("Data-Analyze", "folderOfDayInStandard")

    listOfFunds = []
    count = 0
    for file in os.listdir(folderOfDayInStandard):
        fundCode = file.split("_")[0]
        listOfFunds.append(fundCode)
        
        if not ifGetCorrFromFile and not ifGetDfMergeFromFile:
            if count % 100 == 0:
                print ("count = %s\tfundCode = %s" % (count, fundCode))

            pathFund = os.path.join(folderOfDayInStandard, file)
            df = pd.read_csv(pathFund)
            newName = "AccumulativeNetAssetValue_%s" % fundCode
            df[newName] = df["AccumulativeNetAssetValue"]
            df = df[["DayInStandard", newName]]

            if count == 0:
                dfMerge = df
            else:
                dfMerge = pd.merge(dfMerge, df, on=['DayInStandard'], how='outer')

        count += 1

    if not ifGetCorrFromFile:
        if not ifGetDfMergeFromFile:
            dfMerge.to_csv("data/dfMerge.csv")
        else:
            dfMerge = pd.read_csv("data/dfMerge.csv", index_col=0)

        dfMerge = dfMerge.drop(labels='DayInStandard',axis=1)

        # count correlation
        corr = dfMerge.corr()
        corr.to_csv("data/corr.csv")
    else:
        corr = pd.read_csv("data/corr.csv", index_col=0)

    print ("corr = %s" % corr)
    print ("len(listOfFunds) = %s" % len(listOfFunds))

    nameFund = "AccumulativeNetAssetValue_110011"
    corrFund = corr[nameFund].dropna(axis=0)

    dictOfCorr = {}
    minNumber = 0.98
    nameFund = "110011"
    for fund in listOfFunds:
        if fund == nameFund:
            continue

        nameDf = "AccumulativeNetAssetValue_%s" % fund

        try:
            corrSingle = corrFund[nameDf]

            corrSingle = float("%.1f" % corrSingle)
            if corrSingle not in dictOfCorr:
                dictOfCorr[corrSingle] = 1
            else:
                dictOfCorr[corrSingle] += 1
        except:
            continue

    # show it in image
    plt.figure(figsize=(10, 5))
    plt.ylim((0, 3000))
    ax = plt.gca()
    # no line in right and top border
    ax.spines['right'].set_color('none')
    ax.spines['top'].set_color('none')
    plt.xlabel("Correlation")
    plt.ylabel("Count")
    for key in sorted(dictOfCorr.keys()):
        if key != 'nan':
            if key == minNumber:
                plt.bar("<=%s" % str(key), dictOfCorr[key], width=0.8, fc='k')
            else:
                plt.bar(str(key), dictOfCorr[key], width=0.8, fc='k')

    plt.savefig("./image/correlation_%s.png" % nameFund)

    print ("END.")


def getCorrelationMatrixForAllFunds(ifGetCorrFromFile = True, ifGetDfMergeFromFile = True):
    print ("Begin to get Pearson's correlation matrix for all funds...")
    # read config file
    cf = configparser.ConfigParser()
    cf.read("config/config.ini")
    folderOfDayInStandard = cf.get("Data-Analyze", "folderOfDayInStandard")

    listOfFunds = []
    count = 0
    for file in os.listdir(folderOfDayInStandard):
        fundCode = file.split("_")[0]

        listOfFunds.append(fundCode)

        if not ifGetCorrFromFile and not ifGetDfMergeFromFile:
            pathFund = os.path.join(folderOfDayInStandard, file)
            df = pd.read_csv(pathFund)
            newName = "AccumulativeNetAssetValue_%s" % fundCode
            df[newName] = df["AccumulativeNetAssetValue"]
            df = df[["DayInStandard", newName]]

            if count == 0:
                dfMerge = df
            else:
                dfMerge = pd.merge(dfMerge, df, on=['DayInStandard'], how='outer')

        count += 1

    if not ifGetCorrFromFile:
        if not ifGetDfMergeFromFile:
            dfMerge.to_csv("data/dfMerge.csv")
        else:
            dfMerge = pd.read_csv("data/dfMerge.csv", index_col=0)

        dfMerge = dfMerge.drop(labels='DayInStandard',axis=1)

        # count correlation
        corr = dfMerge.corr()
        corr.to_csv("data/corr.csv")
    else:
        corr = pd.read_csv("data/corr.csv", index_col=0)

    print (corr)
    print ("len(listOfFunds) = %s" % len(listOfFunds))

    dictOfMaxCorr = {}
    minNumber = 0.98
    for fund in listOfFunds:
        nameDf = "AccumulativeNetAssetValue_%s" % fund

        # nameDf don't exist in corr
        try:
            corrSingle = corr[nameDf].dropna(axis=0)
            corrWithoutSelf = corrSingle.drop(labels=nameDf, axis=0)
        except:
            continue

        maxCorr = float(corrWithoutSelf.max())
        maxCorr = float("%.3f" % maxCorr)
        if maxCorr <= minNumber:
            maxCorr = minNumber
        if maxCorr not in dictOfMaxCorr:
            dictOfMaxCorr[maxCorr] = 1
        else:
            dictOfMaxCorr[maxCorr] += 1

    print (dictOfMaxCorr)

    # show it in image
    plt.figure(figsize=(15, 5))
    plt.ylim((0, 5000))
    ax = plt.gca()
    # no line in right and top border
    ax.spines['right'].set_color('none')
    ax.spines['top'].set_color('none')
    plt.xlabel("Maximum correlation")
    plt.ylabel("Count")
    for key in sorted(dictOfMaxCorr.keys()):
        if key != 'nan':
            if key == minNumber:
                plt.bar("<=%s" % str(key), dictOfMaxCorr[key], width=0.8, fc='k')
            else:
                plt.bar(str(key), dictOfMaxCorr[key], width=0.8, fc='k')

    plt.savefig("./image/maximum_correlation.png")

    print ("END.")


def getAllElementsInPortfolio():
    # read config file
    cf = configparser.ConfigParser()
    cf.read("config/config.ini")
    folderOfPortfolio = cf.get("Data-Crawler", "folderOfPortfolio")
    pathOfDfMergeFullElements = cf.get("Data-Analyze", "pathOfDfMergeFullElements")

    count = 0
    countAllElements = 0
    for file in os.listdir(folderOfPortfolio):
        if count >= 100000000000:
            break

        if count % 100 == 0:
            print ("count = %s\tfile = %s" % (count, file))
        pathFund = os.path.join(folderOfPortfolio, file)
        df = pd.read_csv(pathFund)

        # add stock code, because, "中国平安" can represents two stocks, "601318" and "02318"
        df["FullElements"] = df["ElementType"] + "_" + df["Code"].astype(str) + "_" + df["Name"]
        dfFullElements = df["FullElements"]
        countAllElements += dfFullElements.shape[0]

        if count == 0:
            dfMergeFullElements = dfFullElements
        else:
            dfMergeFullElements = pd.merge(dfMergeFullElements, dfFullElements, on=['FullElements'], how='outer')

        count += 1

    # merge is not useful
    dfMergeFullElements = dfMergeFullElements.drop_duplicates(subset=['FullElements'],keep='first')
    dfMergeFullElements = dfMergeFullElements.sort_values(by='FullElements')
    dfMergeFullElements.reset_index(drop=True, inplace=True)
    print (dfMergeFullElements)
    print ("countAllElements = %s" % countAllElements)

    dfMergeFullElements.to_csv(pathOfDfMergeFullElements)

def getSparseMatrixForPortfolioInAllFunds():
    # read config file
    cf = configparser.ConfigParser()
    cf.read("config/config.ini")
    folderOfPortfolio = cf.get("Data-Crawler", "folderOfPortfolio")
    pathOfDfMergeFullElements = cf.get("Data-Analyze", "pathOfDfMergeFullElements")
    pathOfDfSparsePortfolio = cf.get("Data-Analyze", "pathOfDfSparsePortfolio")

    if not os.path.exists(pathOfDfMergeFullElements):
        getAllElementsInPortfolio()

    dfSparsePortfolio = pd.read_csv(pathOfDfMergeFullElements, index_col=0)
    
    count = 0
    for file in os.listdir(folderOfPortfolio):
        fundCode = file.split("_")[0]

        if count % 100 == 0:
            print ("count = %s\tfundCode = %s" % (count, fundCode))

        pathFund = os.path.join(folderOfPortfolio, file)
        df = pd.read_csv(pathFund)
        df["FullElements"] = df["ElementType"] + "_" + df["Code"].astype(str) + "_" + df["Name"]
        # fund "090019" have two bonds "bond_170207_17国开07"
        df = df.drop_duplicates(subset=['FullElements'],keep='first')\
            .fillna(0)\
            .replace(-1, 0)

        try:
            s = df.set_index('FullElements')['Ratio']
            dfSparsePortfolio[fundCode] = dfSparsePortfolio["FullElements"].map(s)
        except Exception as e:
            print (fundCode)
            print (df)
            print (s)
            print (dfSparsePortfolio)
            raise e

        count += 1

    print (dfSparsePortfolio)
    dfSparsePortfolio.to_csv(pathOfDfSparsePortfolio)


def getCosineOfSparseMatrixForPortfolio():
    '''
        use sklearn to get the cosine similarity of portfolio
        '1' means these 2 portfolios are similar, also means the degree equals to 0
    '''
    # read config file
    cf = configparser.ConfigParser()
    cf.read("config/config.ini")
    pathOfDfSparsePortfolio = cf.get("Data-Analyze", "pathOfDfSparsePortfolio")
    pathOfDfCosineSimilarityForPortfolio = cf.get("Data-Analyze", "pathOfDfCosineSimilarityForPortfolio")

    if not os.path.exists(pathOfDfSparsePortfolio):
        getSparseMatrixForPortfolioInAllFunds()

    dfSparsePortfolio = pd.read_csv(pathOfDfSparsePortfolio, index_col=0)
    dfSparsePortfolio = dfSparsePortfolio.drop(labels="FullElements", axis=1)
    header = dfSparsePortfolio.columns

    # count cosine similarity mannually
    if False:
        dfSparsePortfolio = dfSparsePortfolio.replace(-1, 0)
        dfSparsePortfolio["AA"] = dfSparsePortfolio["150343"] * dfSparsePortfolio["150343"]
        dfSparsePortfolio["BB"] = dfSparsePortfolio["001347"] * dfSparsePortfolio["001347"]
        dfSparsePortfolio["AB"] = dfSparsePortfolio["150343"] * dfSparsePortfolio["001347"]
        print (dfSparsePortfolio["AA"].sum())
        print (dfSparsePortfolio["AB"].sum())
        print (dfSparsePortfolio["BB"].sum())

    # cosine_similarity required
    # fill nan with 0, 0 is meaningless when count cosine
    # -1 represent not found, so we should set this be zero
    dfSparsePortfolio = dfSparsePortfolio.T.fillna(0).replace(-1, 0)
    print (dfSparsePortfolio)

    cosineSimilarityForPortfolio = cosine_similarity(dfSparsePortfolio)
    dfCosineSimilarityForPortfolio = pd.DataFrame(cosineSimilarityForPortfolio, columns=header)
    print (dfCosineSimilarityForPortfolio)

    dfCosineSimilarityForPortfolio.to_csv(pathOfDfCosineSimilarityForPortfolio)

def analyzeCosineForOneFund():
    # read config file
    cf = configparser.ConfigParser()
    cf.read("config/config.ini")
    pathOfDfCosineSimilarityForPortfolio = cf.get("Data-Analyze", "pathOfDfCosineSimilarityForPortfolio")

    if not os.path.exists(pathOfDfCosineSimilarityForPortfolio):
        getCosineOfSparseMatrixForPortfolio()

    dfCosineSimilarityForPortfolio = pd.read_csv(pathOfDfCosineSimilarityForPortfolio, index_col=0)
    nameFund = "110011"
    cosineFund = dfCosineSimilarityForPortfolio[nameFund].dropna(axis=0)
    print ("cosineFund = %s" % cosineFund)

    dictOfBucket = {}
    for i, v in cosineFund.items():
        name = dfCosineSimilarityForPortfolio.columns.values[i]
        if name == nameFund:
            continue

        cosine = "%.1f" % v
        if cosine == "1.0":
            print (name)
        if cosine not in dictOfBucket.keys():
            dictOfBucket[cosine] = 1
        else:
            dictOfBucket[cosine] += 1

    print (dictOfBucket)

    # show it in image
    plt.figure(figsize=(10, 5))
    plt.ylim((0, 4000))
    ax = plt.gca()
    # no line in right and top border
    ax.spines['right'].set_color('none')
    ax.spines['top'].set_color('none')
    plt.xlabel("Cosine")
    plt.ylabel("Count")
    for key in sorted(dictOfBucket):
        plt.bar(key, dictOfBucket[key], width=0.8, fc='k')

    plt.savefig("./image/cosine_%s.png" % nameFund)


def compareCosineAndPearsonCorr(ifFetchCosineFundFromFile = True, ifFetchCorrFundFromFile = True):
    # read config file
    cf = configparser.ConfigParser()
    cf.read("config/config.ini")
    pathOfDfCosineSimilarityForPortfolio = cf.get("Data-Analyze", "pathOfDfCosineSimilarityForPortfolio")

    if not ifFetchCosineFundFromFile:
        dfCosineSimilarityForPortfolio = pd.read_csv(pathOfDfCosineSimilarityForPortfolio, index_col=0)
        header = dfCosineSimilarityForPortfolio.columns
        dfCosineSimilarityForPortfolio.set_index(header, inplace=True)
        nameFund = "110011"
        cosineFund = dfCosineSimilarityForPortfolio[nameFund].dropna(axis=0)
        cosineFund.to_csv("data/cosineFundFor110011.csv")
        
    cosineFund = pd.read_csv("data/cosineFundFor110011.csv", index_col=0)
    cosineFund["b"] = cosineFund.T.columns
    cosineFund["a"] = "AccumulativeNetAssetValue_" + cosineFund["b"].apply(str)
    cosineFund = cosineFund.drop(labels='b',axis=1)
    print ("cosineFund = \n%s" % cosineFund)

    if not ifFetchCorrFundFromFile:
        corr = pd.read_csv("data/corr.csv", index_col=0)
        nameFund = "AccumulativeNetAssetValue_110011"
        corrFund = corr[nameFund].dropna(axis=0)
        corrFund.to_csv("data/corrFundFor110011.csv")

    corrFund = pd.read_csv("data/corrFundFor110011.csv", index_col=0)
    corrFund["a"] = corrFund.T.columns
    
    df = pd.merge(cosineFund, corrFund, on=['a'], how='outer')

    # delete useless columns
    df = df.drop(labels='a', axis=1)
    print (df.corr())
    df.plot.scatter(x='110011', y='AccumulativeNetAssetValue_110011', c='k')
    plt.xlim((0, 1.0))
    plt.ylim((-1.0, 1.0))
    ax = plt.gca()
    # no line in right and top border
    ax.spines['right'].set_color('none')
    ax.spines['top'].set_color('none')
    plt.xlabel("Cosine")
    plt.ylabel("Pearson's correlation")
    plt.savefig("./image/cosine_PearsonCorr_110011.png")


if __name__ == "__main__":
    fire.Fire()